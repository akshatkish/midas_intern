{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import  matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = 'x'\n",
    "access_secret = 'y'\n",
    "consumer_key = 'z'\n",
    "consumer_secret = 'w'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "access credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_object = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth_object.set_access_token(access_token, access_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tweepy.API(auth_object, wait_on_rate_limit=True, wait_on_rate_limit_notify=True, compression=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authorization complete with data link formed by api object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# initialization of a list to hold all Tweets\n",
    "def get_all_tweets(screen_name):\n",
    "    all_the_tweets = []\n",
    "\n",
    "    # We will get the tweets with multiple requests of 200 tweets each\n",
    "\n",
    "    new_tweets = api.user_timeline(screen_name=screen_name, count=200)\n",
    "\n",
    "    # saving the most recent tweets\n",
    "\n",
    "    all_the_tweets.extend(new_tweets)\n",
    "\n",
    "    # save id of 1 less than the oldest tweet\n",
    "\n",
    "    oldest_tweet = all_the_tweets[-1].id - 1\n",
    "\n",
    "    # grabbing tweets till none are left\n",
    "\n",
    "    while len(new_tweets):\n",
    "        # The max_id param will be used subsequently to prevent duplicates\n",
    "        new_tweets = api.user_timeline(screen_name=screen_name,\n",
    "        count=200, max_id=oldest_tweet)\n",
    "\n",
    "    # save most recent tweets\n",
    "\n",
    "    all_the_tweets.extend(new_tweets)\n",
    "\n",
    "    # id is updated to oldest tweet - 1 to keep track\n",
    "\n",
    "    oldest_tweet = all_the_tweets[-1].id - 1\n",
    "    print ('...%s tweets have been downloaded so far' % len(all_the_tweets))\n",
    "\n",
    "    # transforming the tweets into a 2D array that will be used to populate the csv\n",
    "\n",
    "    outtweets = [[tweet.id_str, tweet.created_at,\n",
    "    tweet.text.encode('utf-8')] for tweet in all_the_tweets]\n",
    "\n",
    "    # writing to the csv file\n",
    "\n",
    "    with open(screen_name + '_tweets.csv', 'w', encoding='utf8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['id', 'created_at', 'text'])\n",
    "        writer.writerows(outtweets)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Enter the twitter handle of the person concerned\n",
    "\n",
    "    get_all_tweets(input(\"Enter the twitter handle of the person whose tweets you want to download:- \"))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code returns HTTPConnectionError() object most probably as for a bug in user_timeline function in tweepy due to its Chinese origin and Twitter is banned in China."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_json(tweet):\n",
    "    tweet_dict = {\n",
    "        \"text\": tweet.text,\n",
    "        \"author_name\": tweet.user.screen_name,\n",
    "        #\"date_and_time\":tweet.created_at,\n",
    "        \"No_of_Favorites\":tweet.favorite_count,\n",
    "        \"No_of_retweets\":tweet.retweet_count,\n",
    "    }\n",
    "    with open('tweet.json', 'a', encoding='utf-8') as f:\n",
    "        json.dumps(tweet_dict, f)\n",
    "for tweet in api.user_timeline(id='midasIIITD', count=400):\n",
    "    dump_json(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting json dump in tweet.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('/home/dev/tweet.json') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "data_dict = json.loads(data)\n",
    "print(p.DataFrame(data_dict).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing json data in tabular format"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
